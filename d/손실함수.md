# 손실함수 (Loss Function)

## 정의
손실함수(loss function, cost function, objective function)는 머신러닝·딥러닝 모델이 **예측값**과 **정답(목표값)** 사이의 차이를 정량화한 함수이다. 학습 과정에서 모델 파라미터를 조정하기 위한 **오차 신호(gradient)**를 제공하며, 최적화 알고리즘이 최소화하려는 목표가 된다. 일반적으로 손실값이 작아질수록 모델이 데이터에 잘 맞는 것으로 평가한다.

## 손실함수의 역할
- **학습 신호 제공**: 역전파(backpropagation)를 통해 매개변수에 대한 기울기를 계산한다.  
- **모델 비교**: 동일한 데이터·구조에 대해 다른 모델·하이퍼파라미터의 성능을 정량적으로 비교한다.  
- **학습 안정성 확보**: 적절히 설계된 손실함수는 수치적 안정성을 보장하고, 과적합·과소적합을 방지한다.  
- **문제 특화**: 회귀, 분류, 순서 예측, 강화학습 등 문제 유형에 맞는 손실을 선택함으로써 학습 효율을 높인다.

## 손실함수의 특성
| 특성 | 설명 | 학습에 미치는 영향 |
|------|------|---------------------|
| **볼록성 (Convexity)** | 손실함수가 파라미터 공간에서 볼록하면 전역 최적점을 찾기 쉽다. | 볼록 손실(MSE, MAE 등)은 최적화가 안정적이지만 딥러닝 모델은 비볼록이 일반적이다. |
| **미분 가능성 (Differentiability)** | 역전파를 위해 손실함수는 거의 everywhere에서 미분 가능해야 한다. | 미분이 불가능한 부분은 서브그라디언트나 근사 기법을 사용한다(예: 힌지 손실). |
| **스케일링 (Scaling)** | 손실값의 절대 크기는 학습률 등에 영향을 미친다. | 큰 손실은 학습률 조정을 필요로 하고, 작은 손실은 정밀도가 요구된다. |
| **가중치 (Weighting)** | 샘플·클래스별 가중치를 부여해 불균형 문제를 완화한다. | 가중치를 적절히 조정하면 희소 클래스에 대한 학습이 강화된다. |
| **강건성 (Robustness)** | 이상치(Outlier)에 대한 민감도를 조절한다. | L1 기반 손실은 이상치에 덜 민감하고, L2 기반은 크게 반영한다. |

## 손실함수의 종류

### 회귀 손실함수
| 손실함수 | 수식 | 특징 |
|---|---|---|
| **평균제곱오차 (MSE)** | $\displaystyle \mathcal{L}_{\text{MSE}} = \frac{1}{N}\sum_{i=1}^{N}(y_i-\hat{y}_i)^2$ | L2 손실, 큰 오차에 높은 패널티, 미분 가능, 볼록 |
| **평균절대오차 (MAE)** | $\displaystyle \mathcal{L}_{\text{MAE}} = \frac{1}{N}\sum_{i=1}^{N}|y_i-\hat{y}_i|$ | L1 손실, 이상치에 강건, 비볼록 (절대값 구간에서 미분 불가능) |
| **Huber 손실** | $\displaystyle \mathcal{L}_{\delta} = \begin{cases}\frac{1}{2}(y_i-\hat{y}_i)^2 & |y_i-\hat{y}_i|\le\delta \\ \delta\big(|y_i-\hat{y}_i|-\frac{\delta}{2}\big) & \text{else}\end{cases}$ | 작은 오차는 L2, 큰 오차는 L1, $\delta$ 로 스위칭 조절 |
| **Log‑Cosh 손실** | $\displaystyle \mathcal{L}_{\text{log‑cosh}} = \frac{1}{N}\sum_{i=1}^{N}\log\!\big(\cosh(\hat{y}_i-y_i)\big)$ | 부드러운 L1 대안, 폭발적 오차 억제 |

### 분류 손실함수
| 손실함수 | 수식 | 주요 용도 |
|---|---|---|
| **binary cross‑entropy (BCE)** | $\displaystyle \mathcal{L}_{\text{BCE}} = -\frac{1}{N}\sum_{i=1}^{N}\big[ y_i\log\hat{p}_i + (1-y_i)\log(1-\hat{p}_i) \big]$ | 이진 분류(시그모이드 출력) |
| **categorical cross‑entropy** | $\displaystyle \mathcal{L}_{\text{CE}} = -\frac{1}{N}\sum_{i=1}^{N}\sum_{c=1}^{C} y_{i,c}\log\hat{p}_{i,c}$ | 다중 클래스(소프트맥스 출력) |
| **hinge loss** | $\displaystyle \mathcal{L}_{\text{hinge}} = \frac{1}{N}\sum_{i=1}^{N}\max(0, 1 - y_i \cdot f(\mathbf{x}_i))$ | SVM, 마진 기반 분류 |
| **focal loss** | $\displaystyle \mathcal{L}_{\text{fl}} = -\frac{1}{N}\sum_{i=1}^{N}(1-\hat{p}_i)^{\gamma}\,y_i\log\hat{p}_i$ | 클래스 불균형(특히 객체 검출) |
| **label smoothing** | $\displaystyle \tilde{y}_{i,c}= (1-\epsilon)\,y_{i,c} + \frac{\epsilon}{C}$ → CE 사용 | 과적합 방지, 모델 캘리브레이션 개선 |
| **softmax with temperature** | $\displaystyle \hat{p}_{i,c}= \frac{\exp(z_{i,c}/\tau)}{\sum_{k}\exp(z_{i,k}/\tau)}$ | 온도 $\tau$ 로 확률 분포 조절, 지식 증류 등에 활용 |

### 확률·정보 이론 기반 손실함수
| 손실함수 | 수식 | 활용 예 |
|---|---|---|
| **Kullback‑Leibler 다이버전스 (KL)** | $\displaystyle D_{\text{KL}}(P\|Q) = \sum_{c} P(c)\log\frac{P(c)}{Q(c)}$ | 변분 오토인코더(VAE), 모델 압축 |
| **Negative Log‑Likelihood (NLL)** | $\displaystyle \mathcal{L}_{\text{NLL}} = -\sum_{i}\log p_{\theta}(y_i\mid\mathbf{x}_i)$ | 확률 모델 전체에 적용 가능 |
| **Bernoulli NLL** | $\displaystyle \mathcal{L}= -\sum_i\big[ y_i\log\hat{p}_i + (1-y_i)\log(1-\hat{p}_i) \big]$ | 이진 확률 예측(시그모이드) |

### 시계열·순서 모델 손실함수
| 손실함수 | 수식 | 특징 |
|---|---|---|
| **CTC 손실 (Connectionist Temporal Classification)** | $\displaystyle \mathcal{L}_{\text{CTC}} = -\log p(\mathbf{y}\mid\mathbf{x})$ (동적 프로그래밍) | 정렬이 없는 시퀀스 라벨링(음성·손글씨) |
| **Sequence‑to‑Sequence 손실** | 일반적으로 teacher‑forcing 형태의 **cross‑entropy** | 디코더 입력에 실제 토큰을 사용해 학습 안정화 |

### 강화학습 손실함수
| 손실함수 | 수식 | 비고 |
|---|---|---|
| **Temporal‑Difference (TD) 오류** | $\displaystyle \delta_t = r_t + \gamma V(s_{t+1}) - V(s_t)$ | 가치 함수 업데이트에 사용 |
| **Policy Gradient 손실** | $\displaystyle \mathcal{L}_{\text{PG}} = -\mathbb{E}_{\pi_\theta}\big[ \log \pi_\theta(a|s) \, \hat{A} \big]$ | REINFORCE, PPO 등에서 사용 |
| **Actor‑Critic 손실** | $\displaystyle \mathcal{L}_{\text{AC}} = \mathcal{L}_{\text{PG}} + c\cdot\mathcal{L}_{\text{value}}$ | 정책·가치 함수를 동시에 학습 |

### 특수 목적 손실함수
| 손실함수 | 수식/개념 | 적용 분야 |
|---|---|---|
| **가중치 손실 (Weighted Loss)** | $\displaystyle \mathcal{L} = \frac{1}{N}\sum_i w_i \, \ell(y_i,\hat{y}_i)$ | 클래스 불균형, 샘플 중요도 조정 |
| **Dice Loss** | $\displaystyle \mathcal{L}_{\text{Dice}} = 1 - \frac{2\sum_i y_i\hat{y}_i}{\sum_i y_i + \sum_i \hat{y}_i}$ | 의료·위성 이미지 분할 |
| **IoU (Jaccard) Loss** | $\displaystyle \mathcal{L}_{\text{IoU}} = 1 - \frac{\sum_i y_i\hat{y}_i}{\sum_i y_i + \sum_i \hat{y}_i - \sum_i y_i\hat{y}_i}$ | 객체 검출·세그멘테이션 |
| **Focal Loss** (이미 위에 있음) | $\displaystyle (1-\hat{p})^\gamma$ factor | 작은 확률에 더 큰 페널티 |
| **Perceptual Loss** | $\displaystyle \mathcal{L}_{\text{perc}} = \| \phi(\hat{y}) - \phi(y) \|_2^2$ (사전 훈련된 VGG 등) | 초해상도, 스타일 변환 |
| **Adversarial Loss** | **GAN**: $\mathcal{L}_D = -\mathbb{E}_{x\sim p_{\text{data}}}[\log D(x)] - \mathbb{E}_{z\sim p_z}[\log(1-D(G(z)))]$ | 생성 모델 훈련 |
| **Contrastive Loss** | $\displaystyle \mathcal{L}_{\text{cont}} = \frac{1}{2N}\sum_i \big[ y_i d_i^2 + (1-y_i)\max(0, m-d_i)^2 \big]$ | 자기지도 학습, 쌍 비교 |
| **Triplet Loss** | $\displaystyle \mathcal{L}_{\text{tri}} = \max(0, \, d_{ap} - d_{an} + \alpha)$ | 얼굴 인식·임베딩 학습 |
| **InfoNCE (NT‑Xent) Loss** | $\displaystyle \mathcal{L}_{\text{InfoNCE}} = -\log \frac{\exp(\mathbf{z}_i^\top \mathbf{z}_j / \tau)}{\sum_{k=1}^{K}\exp(\mathbf{z}_i^\top \mathbf{z}_k / \tau)}$ | 자기지도 표현 학습(SimCLR, MoCo) |

## 손실함수 선택 기준
1. **문제 유형**  
   - 회귀 → MSE, MAE, Huber 등  
   - 이진·다중 클래스 분류 → BCE, CE, focal loss 등  
   - 시계열·정렬이 없는 라벨 → CTC, attention‑based loss  
2. **데이터 특성**  
   - **불균형** → 가중치 손실, focal loss, Dice loss  
   - **노이즈·이상치** → MAE, Huber, Log‑Cosh  
3. **모델 구조**  
   - 선형·볼록 모델 → 볼록 손실을 선호(전역 최적 용이)  
   - 깊은 신경망 → 비볼록 손실도 사용 가능하지만 수렴성에 주의  
4. **수치적 안정성**  
   - 로그 연산이 포함된 경우 (`log(0)` 방지) → `epsilon` 클리핑 적용  
   - 큰 값이 발생할 수 있는 경우 → `log‑sum‑exp` 트릭 사용  
5. **학습 효율**  
   - 미분이 쉬운지? (가급적 연속·미분 가능)  
   - 손실값 스케일이 너무 크면 학습률 조정 필요  
6. **평가 지표와의 연관성**  
   - 손실이 직접 평가 지표와 일치하지 않을 수 있음(예: cross‑entropy ↔ accuracy).  
   - 경우에 따라 **커스텀 손실**을 설계해 평가 지표를 직접 반영(예: F1‑loss, MAP‑loss).  

## 손실함수와 최적화 알고리즘의 관계
- 손실함수의 **그래디언트**가 **스무스**하고 **일관된** 경우, **SGD**, **Adam**, **RMSProp** 등 표준 옵티마이저가 안정적으로 작동한다.  
- **비스무스**하거나 **희소**한 그래디언트(예: 힌지 손실)는 **서브그라디언트** 기법 또는 **스무딩**(예: **smooth hinge**)이 필요할 수 있다.  
- **스케일**이 큰 손실(예: KL 다이버전스)에서는 **그레디언트 클리핑**(clip_norm)이나 **학습률 스케줄링**이 효과적이다.  
- **다중 손실**(멀티태스크 학습)에서는 각각의 손실에 가중치를 부여해 **가중합 손실**을 만든 뒤 최적화한다.  

## 구현 예시
아래는 PyTorch와 TensorFlow에서 자주 사용되는 손실 함수들을 정의하고 사용하는 간단한 예시이다.

### PyTorch 예시
```python
import torch
import torch.nn as nn

# 예시 입력(배치 4, 차원 1)
y_true = torch.tensor([[3.0], [0.5], [2.0], [7.0]])
y_pred = torch.tensor([[2.5], [0.0], [2.2], [8.0]], requires_grad=True)

# 1) MSELoss
mse = nn.MSELoss()
loss_mse = mse(y_pred, y_true)
loss_mse.backward()
print('MSE:', loss_mse.item())

# 2) HuberLoss (δ=1.0)
huber = nn.SmoothL1Loss()  # PyTorch에서는 SmoothL1Loss가 Huber와 동일
loss_huber = huber(y_pred, y_true)
print('Huber:', loss_huber.item())

# 3) Binary Cross‑Entropy (시그모이드 포함)
bce = nn.BCEWithLogitsLoss()  # logits 입력을 받음
logits = torch.tensor([[0.8], [-1.2], [2.0], [0.3]], requires_grad=True)
targets = torch.tensor([[1.0], [0.0], [1.0], [0.0]])
loss_bce = bce(logits, targets)
loss_bce.backward()
print('BCE:', loss_bce.item())

# 4) Custom Focal Loss (γ=2)
class FocalLoss(nn.Module):
    def __init__(self, gamma=2.0, reduction='mean'):
        super().__init__()
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, logits, targets):
        prob = torch.sigmoid(logits)
        pt = prob * targets + (1 - prob) * (1 - targets)
        loss = - (1 - pt).pow(self.gamma) * torch.log(pt + 1e-8)
        if self.reduction == 'mean':
            return loss.mean()
        return loss.sum()

focal = FocalLoss(gamma=2.0)
loss_focal = focal(logits, targets)
print('Focal:', loss_focal.item())
```

### TensorFlow/Keras 예시
```python
import tensorflow as tf
from tensorflow.keras import layers, models, losses, optimizers

# 간단한 회귀 모델 정의
model = models.Sequential([
    layers.Dense(64, activation='relu', input_shape=(10,)),
    layers.Dense(1)
])

model.compile(optimizer=optimizers.Adam(0.001),
              loss=losses.MeanSquaredError(),
              metrics=['mae'])

# 임의 데이터
import numpy as np
x = np.random.randn(1000, 10).astype(np.float32)
y = np.sum(x, axis=1, keepdims=True) + np.random.randn(1000, 1) * 0.5

model.fit(x, y, epochs=10, batch_size=32)

# 커스텀 손실: Huber (δ=1.0)
def huber_loss(y_true, y_pred, delta=1.0):
    error = y_true - y_pred
    cond = tf.abs(error) < delta
    squared_loss = 0.5 * tf.square(error)
    linear_loss = delta * tf.abs(error) - 0.5 * tf.square(delta)
    return tf.where(cond, squared_loss, linear_loss)

model.compile(optimizer='adam', loss=huber_loss, metrics=['mae'])
model.fit(x, y, epochs=5)
```

### Custom Loss 구현 팁
1. **벡터화**: `torch`·`tf` 연산을 **배치 차원** 전체에 적용해 속도를 최적화한다.  
2. **수치 안정성**: `log`, `sqrt` 등에 **epsilon**(예: `1e-8`)을 더해 `NaN`을 방지한다.  
3. **자동미분 지원**: `torch.autograd`·`tf.GradientTape`는 기본 연산에 대한 미분을 자동으로 제공하므로, 직접 `grad`를 구현할 필요가 없다.  
4. **가중치/마스크**: `loss = (weight * loss).mean()` 형태로 샘플 가중치를 쉽게 적용할 수 있다.  

## 손실함수와 평가 지표의 차이
- **손실함수**는 **학습 과정**에서 최적화할 목적 함수이며, **미분 가능성**을 핵심으로 설계된다.  
- **평가 지표**(accuracy, F1‑score, BLEU, IoU 등)는 **모델 성능**을 측정하는 기준이며, **비미분**이어도 된다.  
- 경우에 따라 손실과 지표가 서로 상충한다. 예를 들어 **cross‑entropy**를 최소화했지만 **accuracy**가 크게 향상되지 않을 수 있다(클래스 불균형). 이런 경우 **커스텀 손실**(예: F1‑loss)이나 **다중 손실**(cross‑entropy + metric‑based loss) 전략을 사용한다.  

## 최신 연구 동향
| 분야 | 최신 손실·기법 | 핵심 아이디어 |
|------|----------------|----------------|
| **자기지도 학습** | **InfoNCE**, **NT‑Xent**, **Barlow Twins** | 음성·이미지·텍스트에서 **대조학습**을 위해 서로 다른 뷰(view) 간 유사성을 최대화하고, 동일 뷰 간 차이를 최소화 |
| **메타러닝** | **Learnable Loss Weighting**, **HyperLoss** | 메타-optimizers가 손실 함수 자체를 학습해 태스크에 최적화된 손실을 자동 생성 |
| **다중 작업 학습** | **Uncertainty‑Based Weighting**, **GradNorm** | 각 작업의 손실 스케일과 불확실성을 고려해 가중치를 동적으로 조절 |
| **이미지 분할** | **Boundary Loss**, **Tversky Loss**, **Combo Loss** | 경계 정확도와 클래스 불균형을 동시에 다루는 복합 손실 |
| **생성 모델** | **Wasserstein Loss**, **Least Squares GAN**, **StyleGAN2 Loss** | GAN 훈련의 불안정성을 감소시키기 위한 다양한 **거리 측도**와 **스무딩** 기법 |
| **강화학습** | **Soft Actor‑Critic (SAC) loss**, **Maximum Entropy RL** | 정책 탐색을 촉진하기 위해 **엔트로피 보너스**를 손실에 포함 |
| **딥 팩트** | **Sparse Categorical Cross‑Entropy** + **Label Smoothing** | 대규모 라벨셋(예: 언어 모델)에서 **과적합**과 **확률 왜곡**을 완화 |

## 참고 문헌
1. Ian Goodfellow, Yoshua Bengio, Aaron Courville, *Deep Learning*, MIT Press, 2016.  
2. Christopher M. Bishop, *Pattern Recognition and Machine Learning*, Springer, 2006.  
3. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, “Deep Residual Learning for Image Recognition”, **CVPR**, 2016.  
4. Tzu‑Hao Lin, Priya Goyal, Ross Girshick, Kaiming He, Piotr Dollár, “Focal Loss for Dense Object Detection”, **ICCV**, 2017.  
5. Alex Netzer, et al., “A Simple Framework for Contrastive Learning of Visual Representations”, **ICML**, 2020.  
6. J. Huang, et al., “Multitask Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics”, **CVPR**, 2019.  
7. Z. Zhang, et al., “Dice Loss for Data‑imbalanced Multi‑class Image Segmentation”, **Medical Image Analysis**, 2020.  
8. Martin Arjovsky, Soumith Chintala, Léon Bottou, “Wasserstein GAN”, **ICML**, 2017.  
9. Diederik P. Kingma, Max Welling, “Auto‑Encoding Variational Bayes”, **ICLR**, 2014.  
10. Tong Zhang, et al., “Adaptive Loss Weighting for Multi‑Task Learning”, **NeurIPS**, 2022.  

*(위 목록은 대표적인 참고문헌이며, 최신 논문·서적을 검색하여 최신 동향을 확인하시기 바랍니다.)*